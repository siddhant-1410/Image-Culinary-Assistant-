{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654de6d-7a40-4cb8-bb02-e11cd81bbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import os\n",
    "import cv2\n",
    "# Import tensorflow with CPU support if GPU is not available or causing issues\n",
    "# import tensorflow as tf  # Original import\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Force TensorFlow to use CPU\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=\"key\")  # Replace with your Gemini API key\n",
    "\n",
    "# Load the trained image classification model\n",
    "model_path = r\"/content/dish_classification_model1.h5\"  # Ensure the correct path\n",
    "model = load_model(model_path)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Biryani', 'Butter chicken', 'Chapati', 'Chicken tandoori', 'Chole bhature',  \n",
    " 'Dal makhani', 'Dhokla', 'Dosa', 'Gajar halwa', 'Ghevar',  \n",
    " 'Gulab jamun', 'Jalebi', 'Kadai paneer', 'Kathi roll', 'Kebabs',  \n",
    " 'Kofta', 'Masala bhindi', 'Medu vada', 'Pani puri', 'Pav bhaji',  \n",
    " 'Poori', 'Rasgulla', 'Samosa', 'Toor dal', 'Vada pav']\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = img_to_array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_image(image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    predictions = model.predict(image)\n",
    "    class_index = np.argmax(predictions)\n",
    "    confidence = np.max(predictions)\n",
    "    predicted_class = class_labels[class_index]\n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "# Function to process PDFs and find relevant dish\n",
    "def process_pdfs(pdf_folder, dish_name):\n",
    "    pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
    "    matching_pdf = None\n",
    "    for pdf_file in pdf_files:\n",
    "        if dish_name.lower() in pdf_file.lower():\n",
    "            matching_pdf = pdf_file\n",
    "            break\n",
    "    \n",
    "    if not matching_pdf:\n",
    "        return None, None\n",
    "\n",
    "    text = extract_text_from_pdf(os.path.join(pdf_folder, matching_pdf))\n",
    "    return matching_pdf, text\n",
    "\n",
    "# Function to split text into chunks\n",
    "def chunk_text(text, chunk_size=2048, chunk_overlap=400):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# Function to create FAISS vector store\n",
    "def create_vector_store(pdf_name, text):\n",
    "    embedding_model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
    "    dimension = 768\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "    chunks = chunk_text(text)\n",
    "    embeddings = [embedding_model.encode(chunk, convert_to_numpy=True, normalize_embeddings=True) for chunk in chunks]\n",
    "    \n",
    "    if embeddings:\n",
    "        index.add(np.array(embeddings, dtype=np.float32))\n",
    "    \n",
    "    return index, embedding_model, chunks\n",
    "\n",
    "# Function to retrieve relevant chunks\n",
    "def retrieve_relevant_chunks(query, index, embedding_model, chunks, top_k=3):\n",
    "    query_embedding = embedding_model.encode(query, convert_to_numpy=True, normalize_embeddings=True).astype(np.float32)\n",
    "    _, indices = index.search(np.array([query_embedding]), top_k)\n",
    "    return [chunks[i] for i in indices[0] if i < len(chunks)]\n",
    "\n",
    "# Function to generate response using Gemini API\n",
    "def generate_response(prompt):\n",
    "    system_prompt = (\n",
    "        \"You are a professional chef providing complete and well-structured recipes. \"\n",
    "        \"Ensure the response includes all ingredients and steps in a clear, logical order.\"\n",
    "    )\n",
    "    final_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "    response = model.generate_content(final_prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "# Main function to integrate image classification and RAG\n",
    "def main(image_path):\n",
    "    pdf_folder = \"./recipes_pdf\"\n",
    "    \n",
    "    if not os.path.exists(pdf_folder):\n",
    "        print(f\"Folder '{pdf_folder}' does not exist. Please upload PDFs.\")\n",
    "        return\n",
    "    \n",
    "    # Step 1: Predict the dish name from the image\n",
    "    predicted_dish, confidence = predict_image(image_path)\n",
    "    print(f\"Predicted Dish: {predicted_dish} (Confidence: {confidence:.2f})\")\n",
    "    \n",
    "    # Step 2: Retrieve the recipe using RAG\n",
    "    pdf_name, text = process_pdfs(pdf_folder, predicted_dish)\n",
    "    \n",
    "    if not text:\n",
    "        print(f\"No relevant content found for '{predicted_dish}'.\")\n",
    "        return\n",
    "    \n",
    "    index, embedding_model, chunks = create_vector_store(pdf_name, text)\n",
    "    retrieved_texts = retrieve_relevant_chunks(f\"Recipe for {predicted_dish}\", index, embedding_model, chunks)\n",
    "    \n",
    "    if not retrieved_texts:\n",
    "        print(f\"No relevant content found for '{predicted_dish}'.\")\n",
    "        return\n",
    "    \n",
    "    context = \"\\n\".join(retrieved_texts)\n",
    "    print(f\"\\nRetrieved content from {pdf_name}:\")\n",
    "    print(context[:500] + \"...\")  # Display only the first 500 characters\n",
    "    \n",
    "    prompt = f\"Recipe for {predicted_dish}:\\n\\n{context}\\n\\nProvide a well-structured step-by-step guide.\"\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    print(f\"\\nGenerated Recipe for {predicted_dish}:\")\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = r\"/content/dal_makhani.jpeg\"  # Update with your image path\n",
    "    main(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
